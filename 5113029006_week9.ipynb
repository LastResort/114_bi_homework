{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LastResort/114_bi_homework/blob/main/5113029006_week9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#第9週作業：特徵篩選 - 基因演算法 vs 模擬退火\n",
        "# 使用LSTM模型進行股票價格預測\n",
        "\n",
        "###【核心目標】\n",
        "###透過進化演算法自動找出最佳特徵組合，提升股票價格預測模型的性能\n",
        "###【為什麼需要特徵篩選？】\n",
        "1. 不是所有特徵都有用：有些技術指標可能包含重複資訊或雜訊\n",
        "2. 減少過擬合風險：過多特徵會讓模型記住訓練資料的雜訊\n",
        "3. 提高計算效率：更少的特徵意味著更快的訓練速度\n",
        "4. 提升模型泛化能力：只保留真正有價值的特徵"
      ],
      "metadata": {
        "id": "MMk0AvLSlbLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import random\n",
        "import math\n",
        "import warnings\n",
        "import os\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "24qNvJ7Kh-Oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# 初始設定\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"第9週作業：智能特徵篩選 - 基因演算法 vs 模擬退火\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"使用設備: {device}\")\n",
        "\n",
        "OUTPUT_DIR = './outputs/'\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "print(f\"輸出目錄: {OUTPUT_DIR}\\n\")\n",
        "\n",
        "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "plt.rcParams['figure.figsize'] = (14, 6)"
      ],
      "metadata": {
        "id": "NeGtQb4_h_SQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd4143b6-21a5-4f1f-d156-f0fad03ac49f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "第9週作業：智能特徵篩選 - 基因演算法 vs 模擬退火\n",
            "================================================================================\n",
            "使用設備: cuda\n",
            "輸出目錄: ./outputs/\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 資料收集與特徵工程"
      ],
      "metadata": {
        "id": "OvxIjd7IlkBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# [Part 1/6] 資料收集與特徵工程\n",
        "# ============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"[Part 1/6] 資料收集與特徵工程\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "ticker = '6931.TW'\n",
        "start_date = \"2020-01-01\"\n",
        "end_date = \"2024-12-31\"\n",
        "\n",
        "stock_data = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
        "\n",
        "# 處理可能的 MultiIndex (yfinance 有時會返回 MultiIndex DataFrame)\n",
        "if isinstance(stock_data.columns, pd.MultiIndex):\n",
        "    stock_data.columns = stock_data.columns.get_level_values(0)\n",
        "\n",
        "print(f\"下載 {ticker} 資料：{start_date} 至 {end_date}\")\n",
        "print(f\"原始資料形狀：{stock_data.shape}\")\n",
        "\n",
        "# 【為什麼需要這麼多技術指標？】\n",
        "# 目的：讓GA和SA自動找出哪些指標真正有用\n",
        "# 設計理念：\n",
        "# 1. 刻意加入多樣化的指標（趨勢、動量、波動度、成交量）\n",
        "# 2. 包含一些「看似有用但實際無用」的特徵（如星期幾、雜訊）\n",
        "# 3. 讓演算法通過實驗學習哪些特徵真正有價值\n",
        "# 模擬真實情況：我們通常不確定哪些特徵最有效。\n",
        "print(\"\\n計算技術指標...\")\n",
        "\n",
        "# ========================================\n",
        "# 類別 1：趨勢指標\n",
        "# ========================================\n",
        "stock_data['SMA_5'] = stock_data['Close'].rolling(window=5).mean()\n",
        "stock_data['SMA_10'] = stock_data['Close'].rolling(window=10).mean()\n",
        "stock_data['SMA_20'] = stock_data['Close'].rolling(window=20).mean()\n",
        "stock_data['EMA_12'] = stock_data['Close'].ewm(span=12, adjust=False).mean()\n",
        "stock_data['EMA_26'] = stock_data['Close'].ewm(span=26, adjust=False).mean()\n",
        "\n",
        "ema_12 = stock_data['Close'].ewm(span=12, adjust=False).mean()\n",
        "ema_26 = stock_data['Close'].ewm(span=26, adjust=False).mean()\n",
        "stock_data['MACD'] = ema_12 - ema_26\n",
        "stock_data['MACD_SIGNAL'] = stock_data['MACD'].ewm(span=9, adjust=False).mean()\n",
        "stock_data['MACD_HIST'] = stock_data['MACD'] - stock_data['MACD_SIGNAL']\n",
        "\n",
        "# ========================================\n",
        "# 類別 2：動量震盪指標\n",
        "# ========================================\n",
        "delta = stock_data['Close'].diff()\n",
        "gain = delta.mask(delta < 0, 0)\n",
        "loss = -delta.mask(delta > 0, 0)\n",
        "avg_gain = gain.ewm(com=13, min_periods=14).mean()\n",
        "avg_loss = loss.ewm(com=13, min_periods=14).mean()\n",
        "rs = avg_gain / avg_loss\n",
        "stock_data['RSI_14'] = 100 - (100 / (1 + rs))\n",
        "\n",
        "low_14 = stock_data['Low'].rolling(window=14).min()\n",
        "high_14 = stock_data['High'].rolling(window=14).max()\n",
        "stock_data['STOCH_K'] = 100 * ((stock_data['Close'] - low_14) / (high_14 - low_14))\n",
        "stock_data['STOCH_D'] = stock_data['STOCH_K'].rolling(window=3).mean()\n",
        "\n",
        "stock_data['ROC'] = ((stock_data['Close'] - stock_data['Close'].shift(12)) /\n",
        "                     stock_data['Close'].shift(12)) * 100\n",
        "\n",
        "tp = (stock_data['High'] + stock_data['Low'] + stock_data['Close']) / 3.0\n",
        "sma_tp_20 = tp.rolling(20).mean()\n",
        "mean_dev_20 = (tp - sma_tp_20).abs().rolling(20).mean()\n",
        "stock_data['CCI_20'] = (tp - sma_tp_20) / (0.015 * (mean_dev_20 + 1e-8))\n",
        "\n",
        "# ========================================\n",
        "# 類別 3：波動度指標\n",
        "# ========================================\n",
        "bb_mid = stock_data['Close'].rolling(20).mean()\n",
        "if isinstance(bb_mid, pd.DataFrame): bb_mid = bb_mid.iloc[:, 0]\n",
        "bb_std = stock_data['Close'].rolling(20).std()\n",
        "if isinstance(bb_std, pd.DataFrame): bb_std = bb_std.iloc[:, 0]\n",
        "\n",
        "stock_data['BB_MID_20'] = bb_mid.astype(float)\n",
        "stock_data['BB_UP_20'] = (bb_mid + 2 * bb_std).astype(float)\n",
        "stock_data['BB_LOW_20'] = (bb_mid - 2 * bb_std).astype(float)\n",
        "bb_width_20 = (stock_data['BB_UP_20'] - stock_data['BB_LOW_20']) / (bb_mid + 1e-8)\n",
        "if isinstance(bb_width_20, pd.DataFrame): bb_width_20 = bb_width_20.iloc[:, 0]\n",
        "stock_data['BB_WIDTH_20'] = bb_width_20.astype(float)\n",
        "\n",
        "hl = stock_data['High'] - stock_data['Low']\n",
        "hc = (stock_data['High'] - stock_data['Close'].shift(1)).abs()\n",
        "lc = (stock_data['Low'] - stock_data['Close'].shift(1)).abs()\n",
        "tr = pd.concat([hl, hc, lc], axis=1).max(axis=1)\n",
        "stock_data['ATR_14'] = tr.rolling(window=14, min_periods=14).mean()\n",
        "\n",
        "log_ret = np.log(stock_data['Close'] / stock_data['Close'].shift(1))\n",
        "stock_data['HV_30'] = log_ret.rolling(30).std() * np.sqrt(252)\n",
        "\n",
        "hl_range = (stock_data['High'] - stock_data['Low']).abs()\n",
        "ema_hl_10 = hl_range.ewm(span=10, adjust=False).mean()\n",
        "stock_data['ChaikinVol_10'] = 100.0 * (ema_hl_10 - ema_hl_10.shift(10)) / (ema_hl_10.shift(10) + 1e-8)\n",
        "\n",
        "# ========================================\n",
        "# 類別 4：成交量指標\n",
        "# ========================================\n",
        "price_diff = stock_data['Close'].diff()\n",
        "volume_direction = np.where(price_diff > 0, stock_data['Volume'],\n",
        "                            np.where(price_diff < 0, -stock_data['Volume'], 0))\n",
        "stock_data['OBV'] = volume_direction.cumsum()\n",
        "\n",
        "vwap_num = (tp * stock_data['Volume']).cumsum()\n",
        "vwap_den = stock_data['Volume'].cumsum()\n",
        "stock_data['VWAP'] = vwap_num / (vwap_den + 1e-8)\n",
        "\n",
        "vol_ma_s = stock_data['Volume'].rolling(14).mean()\n",
        "vol_ma_l = stock_data['Volume'].rolling(28).mean()\n",
        "stock_data['VolOsc'] = 100 * (vol_ma_s - vol_ma_l) / (vol_ma_l + 1e-8)\n",
        "\n",
        "# ========================================\n",
        "# 測試用特徵（包含無用/有害特徵）\n",
        "# ========================================\n",
        "# 這些特徵看起來合理，但實際對預測幫助不大\n",
        "# 需要通過實驗發現這些特徵的價值\n",
        "\n",
        "## 時間特徵（對股價預測通常無效）\n",
        "# 為什麼時間特徵無效？股市沒有\"星期一必漲\"這種規律\n",
        "stock_data['WEEKDAY_ENC'] = stock_data.index.dayofweek.astype(float) # 週幾 (0-6)\n",
        "stock_data['MONTH_ENC'] = stock_data.index.month.astype(float) # 月份 (1-12)\n",
        "## 加入雜訊的特徵（直接使用當前數據長度）\n",
        "stock_data['NOISE_VOL'] = stock_data['Volume'].astype(float) + np.random.randn(len(stock_data)) * 1000\n",
        "\n",
        "# ========================================\n",
        "# 創建目標變數\n",
        "# ========================================\n",
        "# 為什麼用shift(-1)？我們要預測明天的收盤價，所以目標是未來一天的價格\n",
        "stock_data['Target'] = stock_data['Close'].shift(-1)\n",
        "stock_data = stock_data.dropna()\n",
        "\n",
        "# 收集所有特徵名稱（排除原始OHLCV和目標變數）\n",
        "ALL_FEATURES = [col for col in stock_data.columns if col not in\n",
        "                ['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close', 'Target']]\n",
        "print(f\"總特徵數: {len(ALL_FEATURES)}\")\n",
        "print(f\"特徵列表前10個: {ALL_FEATURES[:10]}\")"
      ],
      "metadata": {
        "id": "zyJ959FViGpI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b669f32b-0eb7-41ab-b87e-0a94b34cc8b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "[Part 1/6] 資料收集與特徵工程\n",
            "================================================================================\n",
            "下載 6931.TW 資料：2020-01-01 至 2024-12-31\n",
            "原始資料形狀：(484, 5)\n",
            "\n",
            "計算技術指標...\n",
            "總特徵數: 26\n",
            "特徵列表前10個: ['SMA_5', 'SMA_10', 'SMA_20', 'EMA_12', 'EMA_26', 'MACD', 'MACD_SIGNAL', 'MACD_HIST', 'RSI_14', 'STOCH_K']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 資料分割與預處理"
      ],
      "metadata": {
        "id": "yYokxW2slpkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ============================================================================\n",
        "# [Part 2/6] 資料分割與預處理\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"[Part 2/6] 資料分割與預處理\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "train_size = int(len(stock_data) * 0.7)\n",
        "val_size = int(len(stock_data) * 0.15)\n",
        "\n",
        "train_data = stock_data[:train_size]\n",
        "val_data = stock_data[train_size:train_size + val_size]\n",
        "test_data = stock_data[train_size + val_size:]\n",
        "\n",
        "X_train = train_data[ALL_FEATURES]\n",
        "y_train = train_data['Target']\n",
        "X_val = val_data[ALL_FEATURES]\n",
        "y_val = val_data['Target']\n",
        "X_test = test_data[ALL_FEATURES]\n",
        "y_test = test_data['Target']\n",
        "\n",
        "print(f\"訓練集: {len(X_train)} 筆\")\n",
        "print(f\"驗證集: {len(X_val)} 筆\")\n",
        "print(f\"測試集: {len(X_test)} 筆\")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# ========================================\n",
        "# 創建時間序列\n",
        "# ========================================\n",
        "# 【為什麼需要lookback？】\n",
        "# LSTM需要「一段時間的歷史資料」來預測未來\n",
        "#\n",
        "# 【如何運作】\n",
        "# lookback = 10 表示用過去10天的資料預測明天\n",
        "#\n",
        "# 舉例：\n",
        "# 輸入：[第1-10天的特徵] → 輸出：第11天的價格\n",
        "# 輸入：[第2-11天的特徵] → 輸出：第12天的價格\n",
        "# ...\n",
        "#\n",
        "# 【資料形狀變化】\n",
        "# 原始：(樣本數, 特徵數)\n",
        "# 轉換後：(樣本數-lookback, lookback, 特徵數)\n",
        "#         = (批次, 時間步, 特徵)\n",
        "\n",
        "lookback_period = 10\n",
        "\n",
        "def create_sequences(X, y, lookback):\n",
        "    Xs, ys = [], []\n",
        "    for i in range(len(X) - lookback):\n",
        "        Xs.append(X[i:i+lookback])\n",
        "        ys.append(y[i+lookback])\n",
        "    return np.array(Xs), np.array(ys)\n",
        "\n",
        "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train.values, lookback_period)\n",
        "X_val_seq, y_val_seq = create_sequences(X_val_scaled, y_val.values, lookback_period)\n",
        "X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test.values, lookback_period)\n",
        "\n",
        "print(f\"\\n時間序列形狀:\")\n",
        "print(f\"  訓練集: {X_train_seq.shape}\")\n",
        "print(f\"  驗證集: {X_val_seq.shape}\")\n",
        "print(f\"  測試集: {X_test_seq.shape}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "IqWZNgJODm-z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea7f01ac-4d5b-47c5-b29f-89471c415f7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "[Part 2/6] 資料分割與預處理\n",
            "================================================================================\n",
            "訓練集: 311 筆\n",
            "驗證集: 66 筆\n",
            "測試集: 68 筆\n",
            "\n",
            "時間序列形狀:\n",
            "  訓練集: (301, 10, 26)\n",
            "  驗證集: (56, 10, 26)\n",
            "  測試集: (58, 10, 26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 模型定義"
      ],
      "metadata": {
        "id": "zTLO0ryWlsX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# [Part 3/6] 模型定義\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"[Part 3/6] 模型定義\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class LSTMRegressor(nn.Module):\n",
        "    \"\"\"\n",
        "    LSTM股價預測模型\n",
        "\n",
        "    【架構說明】\n",
        "    Input → LSTM層 → Dropout → 全連接層 → Output\n",
        "\n",
        "    【為什麼用LSTM？】\n",
        "    1. 能記住長期依賴關係（Long Short-Term Memory）\n",
        "    2. 避免梯度消失問題（相比傳統RNN）\n",
        "    3. 適合時間序列預測\n",
        "\n",
        "    【架構細節】\n",
        "    1. LSTM層：\n",
        "       - 學習時間序列模式\n",
        "       - hidden_dim控制記憶容量（越大越複雜）\n",
        "       - num_layers控制深度（多層可學習更複雜模式）\n",
        "\n",
        "    2. Dropout層：\n",
        "       - 隨機關閉部分神經元\n",
        "       - 防止過擬合\n",
        "\n",
        "    3. 全連接層：\n",
        "       - 將LSTM輸出映射到預測值\n",
        "       - 使用ReLU激活函數增加非線性\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, hidden_dim=128, num_layers=2, dropout=0.2, output_dim=1):\n",
        "        \"\"\"\n",
        "        初始化模型\n",
        "\n",
        "        參數說明：\n",
        "        - input_dim: 輸入特徵數量（由選擇的特徵決定）\n",
        "        - hidden_dim: LSTM隱藏層大小\n",
        "          * 越大：學習能力越強，但計算成本高、容易過擬合\n",
        "          * 越小：訓練快，但表達能力受限\n",
        "          * 建議：64-256之間\n",
        "\n",
        "        - num_layers: LSTM層數\n",
        "          * 1層：簡單模式\n",
        "          * 2-3層：複雜模式（推薦）\n",
        "          * >3層：容易過擬合\n",
        "\n",
        "        - dropout: Dropout比例\n",
        "          * 0.1-0.3：常用範圍\n",
        "          * 太高：模型欠擬合\n",
        "          * 太低：容易過擬合\n",
        "\n",
        "        - output_dim: 輸出維度（預測明天的收盤價，所以是1）\n",
        "        \"\"\"\n",
        "\n",
        "        super(LSTMRegressor, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        # 為什麼用batch_first=True？讓資料格式為[批次, 時間, 特徵]，更直觀\n",
        "        # LSTM 主體\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout\n",
        "        )\n",
        "\n",
        "        # 全連接輸出層\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim//2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(hidden_dim//2, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        前向傳播過程\n",
        "\n",
        "        【如何運作】\n",
        "        1. 初始化隱藏狀態（h0, c0）為零向量\n",
        "        2. LSTM處理整個序列，更新隱藏狀態\n",
        "        3. 取最後時間步的輸出（包含所有歷史資訊的總結）\n",
        "        4. 通過全連接層得到最終預測值\n",
        "\n",
        "        【為什麼只用最後時間步？】\n",
        "        - 最後時間步的輸出已包含整個序列的資訊\n",
        "        - LSTM的設計理念：將變長序列編碼成固定長度向量\n",
        "\n",
        "        參數：\n",
        "        - x: 輸入張量，形狀 (batch_size, seq_len, features)\n",
        "\n",
        "        返回：\n",
        "        - out: 預測值，形狀 (batch_size, 1)\n",
        "        \"\"\"\n",
        "\n",
        "        # x: (batch, seq_len, features)\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
        "\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out[:, -1, :])  # 取最後時間步\n",
        "        return out\n",
        "\n",
        "print(\"LSTM模型定義完成\")\n",
        "\n",
        "def train_model(model, train_loader, val_loader, epochs=30, lr=1e-3, verbose=False):\n",
        "    \"\"\"\n",
        "    訓練LSTM模型\n",
        "\n",
        "    【為什麼這樣設計訓練流程？】\n",
        "    1. Adam優化器：自適應學習率，收斂更快更穩定\n",
        "    2. MSE損失函數：適合回歸問題（最小化預測誤差平方和）\n",
        "    3. Early Stopping：防止過擬合，節省訓練時間\n",
        "\n",
        "    【訓練流程】\n",
        "    For each epoch:\n",
        "        1. 訓練模式：\n",
        "           - 遍歷所有批次\n",
        "           - 計算損失\n",
        "           - 反向傳播\n",
        "           - 更新權重\n",
        "\n",
        "        2. 驗證模式：\n",
        "           - 關閉Dropout和BatchNorm\n",
        "           - 計算驗證損失\n",
        "           - 不更新權重\n",
        "\n",
        "        3. Early Stopping檢查：\n",
        "           - 如果驗證損失改善：重置patience計數器\n",
        "           - 如果驗證損失未改善：增加計數器\n",
        "           - 如果連續patience個epoch未改善：停止訓練\n",
        "\n",
        "    參數說明：\n",
        "    - model: 要訓練的模型\n",
        "    - train_loader: 訓練資料載入器\n",
        "    - val_loader: 驗證資料載入器\n",
        "    - epochs: 最大訓練輪數\n",
        "    - lr: 學習率（Learning Rate）\n",
        "      * 太大：訓練不穩定，可能發散\n",
        "      * 太小：收斂太慢\n",
        "      * 建議：1e-3到1e-4\n",
        "    - verbose: 是否顯示訓練過程\n",
        "\n",
        "    返回：\n",
        "    - model: 訓練好的模型\n",
        "    \"\"\"\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    best_loss = float('inf')\n",
        "    # Early Stopping參數\n",
        "    patience, patience_counter = 10, 0\n",
        "\n",
        "    for ep in range(epochs):\n",
        "        model.train()\n",
        "        for Xb, yb in train_loader:\n",
        "            Xb, yb = Xb.to(device), yb.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(Xb)\n",
        "            loss = criterion(out.squeeze(), yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        model.eval() # 設為評估模式（關閉Dropout）\n",
        "        val_loss = 0\n",
        "        # 為什麼用torch.no_grad？驗證時不需要計算梯度，節省記憶體和時間\n",
        "        with torch.no_grad():\n",
        "            for Xb, yb in val_loader:\n",
        "                Xb, yb = Xb.to(device), yb.to(device)\n",
        "                val_loss += criterion(model(Xb).squeeze(), yb).item()\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        # ========================================\n",
        "        # Early Stopping邏輯\n",
        "        # ========================================\n",
        "        # 為什麼需要Early Stopping？\n",
        "        # 當驗證損失停止改善時，繼續訓練會導致：\n",
        "        # 1. 訓練損失繼續下降（記住訓練資料）\n",
        "        # 2. 驗證損失開始上升（泛化能力變差）\n",
        "        # 3. 浪費時間和計算資源\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                if verbose: print(f\"  Early stopping at epoch {ep+1}\")\n",
        "                break\n",
        "\n",
        "        if verbose and (ep+1) % 10 == 0:\n",
        "            print(f\"  Epoch {ep+1}/{epochs} - Val Loss: {val_loss:.6f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    \"\"\"\n",
        "    評估模型性能\n",
        "\n",
        "    【為什麼用RMSE和MAE？】\n",
        "\n",
        "    1. RMSE（Root Mean Squared Error）均方根誤差\n",
        "       公式：√(Σ(預測-實際)² / n)\n",
        "       特點：\n",
        "       - 對大誤差更敏感（因為有平方項）\n",
        "       - 單位與目標變數相同（如：美元）\n",
        "       - 適合評估極端情況的影響\n",
        "\n",
        "    2. MAE（Mean Absolute Error）平均絕對誤差\n",
        "       公式：Σ|預測-實際| / n\n",
        "       特點：\n",
        "       - 對所有誤差平等對待\n",
        "       - 更穩健（不受異常值影響）\n",
        "       - 更容易解釋\n",
        "\n",
        "    【何時用哪個？】\n",
        "    - RMSE：關注極端錯誤時（如風險管理）\n",
        "    - MAE：關注平均表現時（如日常預測）\n",
        "    - 同時報告：最全面\n",
        "\n",
        "    參數：\n",
        "    - model: 訓練好的模型\n",
        "    - X_test: 測試特徵\n",
        "    - y_test: 測試目標\n",
        "\n",
        "    返回：\n",
        "    - rmse: 均方根誤差\n",
        "    - mae: 平均絕對誤差\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        preds = model(torch.Tensor(X_test).to(device)).cpu().squeeze().numpy()\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
        "    mae = mean_absolute_error(y_test, preds)\n",
        "    return rmse, mae"
      ],
      "metadata": {
        "id": "gY3CVflyircN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f99953d6-8bd1-45fb-e56c-71d77fb619eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "[Part 3/6] 模型定義\n",
            "================================================================================\n",
            "LSTM模型定義完成\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline (全特徵)"
      ],
      "metadata": {
        "id": "pBnDjTuYlv9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# [Part 4/6] 階段1 - Baseline (全特徵)\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"[Part 4/6] 階段1 - Baseline (全特徵)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ========================================\n",
        "# 【為什麼需要Baseline？】\n",
        "# ========================================\n",
        "# 目的：建立比較基準\n",
        "#\n",
        "# 如果GA/SA的結果比Baseline還差，那就失敗了\n",
        "# 如果GA/SA的結果更好，才證明特徵篩選有效\n",
        "#\n",
        "# Baseline策略：使用所有特徵（不做篩選）\n",
        "\n",
        "# ========================================\n",
        "# 創建DataLoader\n",
        "# ========================================\n",
        "# 【為什麼使用DataLoader？】\n",
        "#\n",
        "# 優點：\n",
        "# 1. 自動批次處理\n",
        "#    - 一次處理batch_size個樣本\n",
        "#    - 充分利用GPU並行計算能力\n",
        "#\n",
        "# 2. 自動打亂訓練資料（shuffle=True）\n",
        "#    - 防止模型記住資料順序\n",
        "#    - 每個epoch都有不同的批次組合\n",
        "#    - 提升泛化能力\n",
        "#\n",
        "# 3. 簡化程式碼\n",
        "#    - 不用手動管理批次索引\n",
        "#    - 自動處理最後不足一個批次的資料\n",
        "#\n",
        "# 【batch_size的選擇】\n",
        "# - 太大（如256）：記憶體需求高，泛化能力可能變差\n",
        "# - 太小（如8）：訓練不穩定，速度慢\n",
        "# - 建議：32-64（在計算效率和泛化之間平衡）\n",
        "\n",
        "train_loader_full = DataLoader(\n",
        "    TensorDataset(torch.Tensor(X_train_seq), torch.Tensor(y_train_seq)),\n",
        "    batch_size=32, shuffle=True\n",
        ")\n",
        "val_loader_full = DataLoader(\n",
        "    TensorDataset(torch.Tensor(X_val_seq), torch.Tensor(y_val_seq)),\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "print(\"\\n訓練 LSTM-Baseline...\")\n",
        "trans_baseline = LSTMRegressor(len(ALL_FEATURES)).to(device)\n",
        "trans_baseline = train_model(trans_baseline, train_loader_full, val_loader_full, epochs=50, verbose=True)\n",
        "rmse_trans_base, mae_trans_base = evaluate_model(trans_baseline, X_test_seq, y_test_seq)\n",
        "print(f\"LSTM-Baseline RMSE: {rmse_trans_base:.6f}, MAE: {mae_trans_base:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRIZ4nxTi1ow",
        "outputId": "d7b74005-500d-49d0-8256-a0227a09b1c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "[Part 4/6] 階段1 - Baseline (全特徵)\n",
            "================================================================================\n",
            "\n",
            "訓練 LSTM-Baseline...\n",
            "  Epoch 10/50 - Val Loss: 894.768463\n",
            "  Epoch 20/50 - Val Loss: 810.553162\n",
            "  Early stopping at epoch 22\n",
            "LSTM-Baseline RMSE: 31.364646, MAE: 31.332005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 基因演算法 & 模擬退火"
      ],
      "metadata": {
        "id": "6vsMbuDUlzAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# 特徵子集評估函數\n",
        "# ============================================================================\n",
        "def evaluate_feature_subset(features, model_class, n_trials=3, epochs=20, verbose=False):\n",
        "    \"\"\"\n",
        "    評估特定特徵子集的效能\n",
        "\n",
        "    【為什麼需要這個函數？】\n",
        "    這是GA和SA的核心評估函數（適應度函數）\n",
        "\n",
        "    【如何運作】\n",
        "    1. 接收一組特徵\n",
        "    2. 用這些特徵訓練模型\n",
        "    3. 在驗證集上評估\n",
        "    4. 返回RMSE（越小越好）\n",
        "\n",
        "    【為什麼要多次試驗（n_trials）？】\n",
        "    原因：神經網路訓練有隨機性\n",
        "    - 權重初始化是隨機的\n",
        "    - Dropout是隨機的\n",
        "    - 資料打亂是隨機的\n",
        "\n",
        "    解決方案：\n",
        "    - 訓練n_trials次，取平均\n",
        "    - 減少偶然性的影響\n",
        "    - 得到更可靠的評估\n",
        "\n",
        "    參數：\n",
        "    - features: 特徵名稱列表\n",
        "    - model_class: 模型類別（LSTMRegressor）\n",
        "    - n_trials: 評估次數（減少隨機性）\n",
        "    - epochs: 訓練輪數（不需要太多，因為只是評估）\n",
        "    - verbose: 是否顯示詳細資訊\n",
        "\n",
        "    返回：\n",
        "    - mean_rmse: 平均RMSE\n",
        "    - std_rmse: RMSE的標準差（衡量穩定性）\n",
        "    \"\"\"\n",
        "    # 為什麼至少要有一個特徵 --> 沒有特徵無法訓練模型\n",
        "    if len(features) == 0:\n",
        "        return np.inf, 0 # 返回無窮大，表示這是糟糕的解\n",
        "\n",
        "    # ========================================\n",
        "    # 提取選中的特徵\n",
        "    # ========================================\n",
        "    # 根據特徵名稱找到對應的列索引\n",
        "    f_idx = [ALL_FEATURES.index(f) for f in features]\n",
        "    Xtr = X_train_scaled[:, f_idx]\n",
        "    Xva = X_val_scaled[:, f_idx]\n",
        "    # 創建時間序列\n",
        "    Xtr_seq, ytr_seq = create_sequences(Xtr, y_train.values, lookback_period)\n",
        "    Xva_seq, yva_seq = create_sequences(Xva, y_val.values, lookback_period)\n",
        "    # 創建DataLoader\n",
        "    tr_loader = DataLoader(\n",
        "        TensorDataset(torch.Tensor(Xtr_seq), torch.Tensor(ytr_seq)),\n",
        "        batch_size=32, shuffle=True\n",
        "    )\n",
        "    va_loader = DataLoader(\n",
        "        TensorDataset(torch.Tensor(Xva_seq), torch.Tensor(yva_seq)),\n",
        "        batch_size=32\n",
        "    )\n",
        "    # 多次試驗\n",
        "    scores = []\n",
        "    for trial in range(n_trials):\n",
        "        # 設定不同的隨機種子\n",
        "        # 為什麼？確保每次試驗的初始化不同，但整體可重現\n",
        "        torch.manual_seed(SEED + trial)\n",
        "        np.random.seed(SEED + trial)\n",
        "        # 創建並訓練模型\n",
        "        model = model_class(len(features)).to(device)\n",
        "        model = train_model(model, tr_loader, va_loader, epochs=epochs, verbose=False)\n",
        "        # 評估\n",
        "        rmse, _ = evaluate_model(model, Xva_seq, yva_seq)\n",
        "        scores.append(rmse)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"    Trial {trial+1}/{n_trials}: RMSE = {rmse:.6f}\")\n",
        "\n",
        "    mean_rmse = np.mean(scores)\n",
        "    std_rmse = np.std(scores)\n",
        "\n",
        "    return mean_rmse, std_rmse\n",
        "\n",
        "# ============================================================================\n",
        "# 修改區域：實驗參數設定\n",
        "# ============================================================================\n",
        "#\n",
        "# 作業說明：\n",
        "# 請修改以下參數，進行不同的實驗，觀察參數如何影響結果\n",
        "#\n",
        "# 實驗建議：\n",
        "# 1. 固定其他參數，只改變一個參數（例如：世代數）\n",
        "# 2. 記錄每組實驗的結果（RMSE、特徵數、運行時間）\n",
        "# 3. 分析參數對結果的影響\n",
        "#\n",
        "# ============================================================================\n",
        "\n",
        "# --------------------------------------------\n",
        "# 基因演算法 (GA) 參數\n",
        "# --------------------------------------------\n",
        "# TODO: 修改以下參數進行實驗\n",
        "\n",
        "#ga_generations = 8         # 世代數（建議範圍: 10-25）\n",
        "ga_generations = 15         # 世代數（建議範圍: 10-25）\n",
        "                            # 越多：收斂越好，但時間越長\n",
        "                            # 越少：速度快，但可能收斂不足\n",
        "                            # 建議：先用10試試，如果結果還在改善就增加\n",
        "\n",
        "#ga_pop_size = 20           # 族群大小（建議範圍: 15-30）\n",
        "ga_pop_size = 25           # 族群大小（建議範圍: 15-30）\n",
        "                           # 越大：搜索空間大，多樣性好，不易早熟\n",
        "                           # 越小：速度快，但容易困在局部最優\n",
        "                           # 建議：特徵數越多，族群就要越大\n",
        "\n",
        "#ga_mutation_rate = 0.15    # 變異率（建議範圍: 0.1-0.25）\n",
        "ga_mutation_rate = 0.25    # 變異率（建議範圍: 0.1-0.25）\n",
        "                           # 越高：探索性強，多樣性好，但不穩定\n",
        "                           # 越低：收斂快，但可能困在局部最優\n",
        "\n",
        "# --------------------------------------------\n",
        "# 模擬退火 (SA) 參數\n",
        "# --------------------------------------------\n",
        "# TODO: 修改以下參數進行實驗\n",
        "\n",
        "#sa_T_init = 50             # 初始溫度（建議範圍: 30-100）\n",
        "sa_T_init = 100             # 初始溫度（建議範圍: 30-100）\n",
        "                           # 越高：接受劣解機率大，探索性強\n",
        "                           # 越低：較快收斂到局部最優\n",
        "\n",
        "#sa_cooling_rate = 0.85     # 冷卻率（建議範圍: 0.80-0.95）\n",
        "sa_cooling_rate = 0.95     # 冷卻率（建議範圍: 0.80-0.95）\n",
        "                           # 越高：降溫慢，搜索細緻，但時間長\n",
        "                           # 越低：降溫快，收斂快但可能不夠好\n",
        "\n",
        "sa_T_min = 1               # 最低溫度（建議保持在1）\n",
        "                      # 溫度降到這個值就停止\n",
        "\n",
        "# --------------------------------------------\n",
        "# 通用參數\n",
        "# --------------------------------------------\n",
        "n_trials = 3               # 每個特徵組合評估次數（建議保持在3）\n",
        "                      # 用於減少隨機性影響\n",
        "                      # 太多會很慢，太少結果不穩定\n",
        "\n",
        "epochs_inner = 40          # GA/SA內部評估時的訓練輪數\n",
        "\n",
        "\n",
        "epochs_final = 50          # 最終測試集評估的訓練輪數\n",
        "                     # 與baseline保持一致\n",
        "\n",
        "# ============================================================================\n",
        "# 修改區域結束\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"實驗參數設定\")\n",
        "print(\"=\"*80)\n",
        "print(f\"GA參數: 世代數={ga_generations}, 族群大小={ga_pop_size}, 變異率={ga_mutation_rate}\")\n",
        "print(f\"SA參數: 初始溫度={sa_T_init}, 冷卻率={sa_cooling_rate}\")\n",
        "print(f\"評估參數: 每個組合評估{n_trials}次, 內部訓練{epochs_inner}輪\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ============================================================================\n",
        "# [Part 5/6] 階段2 & 3 - 基因演算法 & 模擬退火\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"[Part 5/6] 階段2 & 3 - 進化演算法特徵篩選\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ========================================\n",
        "# 基因演算法\n",
        "# ========================================\n",
        "def genetic_algorithm(model_class, model_name, generations, pop_size,\n",
        "                     mutation_rate, n_trials, verbose=True):\n",
        "    \"\"\"基因演算法特徵選擇\"\"\"\n",
        "    \"\"\"\n",
        "    基因演算法特徵選擇\n",
        "\n",
        "    【演算法靈感】\n",
        "    模擬生物進化過程：\n",
        "    1. 自然選擇：適者生存\n",
        "    2. 基因交叉：父母特徵混合產生後代\n",
        "    3. 突變：隨機變異保持多樣性\n",
        "\n",
        "    【如何運作】\n",
        "\n",
        "    ┌─────────────────────────────────────────┐\n",
        "    │ 1. 初始化族群                                 │\n",
        "    │    隨機生成pop_size個染色體                         │\n",
        "    │    每個染色體 = [1,0,1,0,...]（特徵選擇）                 │\n",
        "    └─────────────────────────────────────────┘\n",
        "                    ↓\n",
        "    ┌─────────────────────────────────────────┐\n",
        "    │ 2. 評估適應度                                 │\n",
        "    │    對每個個體訓練模型，計算RMSE                       │\n",
        "    │    RMSE越小 = 適應度越高\n",
        "    └─────────────────────────────────────────┘\n",
        "                    ↓\n",
        "    ┌─────────────────────────────────────────┐\n",
        "    │ 3. 選擇（Selection）                              │\n",
        "    │    保留表現最好的一半個體作為父母                      │\n",
        "    │    淘汰表現差的個體                             │\n",
        "    └─────────────────────────────────────────┘\n",
        "                    ↓\n",
        "    ┌─────────────────────────────────────────┐\n",
        "    │ 4. 交叉（Crossover）                              │\n",
        "    │    隨機配對兩個父母                             │\n",
        "    │    在隨機位置切割染色體                           │\n",
        "    │    前半來自父親，後半來自母親                        │\n",
        "    │                                         │\n",
        "    │    父親: [1,1,0,0,1,1]                           │\n",
        "    │    母親: [0,1,1,1,0,0]                           │\n",
        "    │         切割點↑                            │\n",
        "    │    後代: [1,1,0|1,0,0]                           │\n",
        "    └─────────────────────────────────────────┘\n",
        "                    ↓\n",
        "    ┌─────────────────────────────────────────┐\n",
        "    │ 5. 突變（Mutation）                              │\n",
        "    │    以mutation_rate的機率翻轉每個基因\n",
        "    │    [1,1,0,1,0,0] → [1,0,0,1,0,0]                     │\n",
        "    │           ↑翻轉                           │\n",
        "    │    目的：避免早熟收斂、保持多樣性                      │\n",
        "    └─────────────────────────────────────────┘\n",
        "                    ↓\n",
        "    ┌─────────────────────────────────────────┐\n",
        "    │ 6. 重複2-5直到達到世代數                           │\n",
        "    └─────────────────────────────────────────┘\n",
        "\n",
        "    【為什麼有效】\n",
        "    - 好的特徵組合會被保留和傳播\n",
        "    - 壞的特徵組合會被淘汰\n",
        "    - 交叉和突變產生新的組合\n",
        "    - 經過多代進化，族群整體越來越好\n",
        "\n",
        "    參數：\n",
        "    - model_class: 模型類別\n",
        "    - model_name: 模型名稱（用於顯示）\n",
        "    - generations: 進化世代數\n",
        "    - pop_size: 族群大小\n",
        "    - mutation_rate: 變異率\n",
        "    - n_trials: 評估時的試驗次數\n",
        "    - verbose: 是否顯示詳細過程\n",
        "\n",
        "    返回：\n",
        "    - best_features: 最佳特徵列表\n",
        "    - history: 進化歷史記錄\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"基因演算法 - {model_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"參數設定: 世代數={generations}, 族群大小={pop_size}, 變異率={mutation_rate}\")\n",
        "\n",
        "    # ========================================\n",
        "    # 1. 初始化族群\n",
        "    # ========================================\n",
        "    # 【染色體編碼】\n",
        "    # 每個個體是一個二進位陣列，長度 = 特徵數\n",
        "    # [1, 0, 1, 1, 0, ...] 表示選擇第1、3、4個特徵\n",
        "    #\n",
        "    # 為什麼用隨機初始化？\n",
        "    # - 保證多樣性\n",
        "    # - 覆蓋整個搜索空間\n",
        "\n",
        "    population = [np.random.choice([0, 1], len(ALL_FEATURES)) for _ in range(pop_size)]\n",
        "    # 記錄進化歷史\n",
        "    history = {\n",
        "        'best_scores': [], # 每代最佳分數\n",
        "        'mean_scores': [], # 每代平均分數\n",
        "        'worst_scores': [], # 每代最差分數\n",
        "        'best_features': [], # 每代最佳特徵組合\n",
        "        'best_n_features': [] # 每代最佳特徵數量\n",
        "    }\n",
        "\n",
        "    best_individual = None\n",
        "    best_score = float('inf')\n",
        "\n",
        "    # ========================================\n",
        "    # 2. 進化主循環\n",
        "    # ========================================\n",
        "    for gen in range(generations):\n",
        "        print(f\"\\n第 {gen+1}/{generations} 代:\")\n",
        "\n",
        "        # ========================================\n",
        "        # 2.1 評估適應度\n",
        "        # ========================================\n",
        "        scored_population = []\n",
        "        for idx, individual in enumerate(population):\n",
        "            # 解碼：將染色體轉換為特徵列表\n",
        "            selected_features = [f for i, f in enumerate(ALL_FEATURES) if individual[i] == 1]\n",
        "            # 評估這組特徵的性能\n",
        "            if len(selected_features) == 0:\n",
        "                score = np.inf # 沒有特徵 = 最差\n",
        "                std = 0\n",
        "            else:\n",
        "                score, std = evaluate_feature_subset(selected_features, model_class, n_trials=n_trials, epochs=epochs_inner)\n",
        "\n",
        "            scored_population.append((score, std, individual, selected_features))\n",
        "\n",
        "            if verbose and (idx + 1) % 5 == 0:\n",
        "                print(f\"  評估進度: {idx+1}/{pop_size} (當前RMSE: {score:.6f}±{std:.4f}, 特徵數: {len(selected_features)})\")\n",
        "        # 按分數排序\n",
        "        scored_population.sort(key=lambda x: x[0])\n",
        "\n",
        "        # ========================================\n",
        "        # 2.2 記錄統計資訊\n",
        "        # ========================================\n",
        "        scores = [s[0] for s in scored_population if s[0] != np.inf]\n",
        "        if len(scores) > 0:\n",
        "            history['best_scores'].append(scored_population[0][0])\n",
        "            history['mean_scores'].append(np.mean(scores))\n",
        "            history['worst_scores'].append(scored_population[-1][0])\n",
        "            history['best_features'].append(scored_population[0][3])\n",
        "            history['best_n_features'].append(len(scored_population[0][3]))\n",
        "\n",
        "            print(f\"  最佳RMSE: {scored_population[0][0]:.6f}±{scored_population[0][1]:.4f} (特徵數: {len(scored_population[0][3])})\")\n",
        "            print(f\"  平均RMSE: {np.mean(scores):.6f}\")\n",
        "            print(f\"  最差RMSE: {scored_population[-1][0]:.6f}\")\n",
        "        # 更新全局最佳\n",
        "        if scored_population[0][0] < best_score:\n",
        "            best_score = scored_population[0][0]\n",
        "            best_individual = scored_population[0][2].copy()\n",
        "            print(f\"  發現新的最佳解！RMSE = {best_score:.6f}\")\n",
        "\n",
        "\n",
        "        # ========================================\n",
        "        # 2.3 選擇（Selection）\n",
        "        # ========================================\n",
        "        # 【選擇策略】\n",
        "        # 1. 精英保留（Elitism）：直接保留最好的20%\n",
        "        #    - 確保好的解不會丟失\n",
        "        # 2. 剩餘80%由父母交叉產生\n",
        "        #    - 保持多樣性\n",
        "        n_parents = pop_size // 2 # 前50%作為父母\n",
        "        parents = [ind for _, _, ind, _ in scored_population[:n_parents]]\n",
        "\n",
        "        n_elite = pop_size // 5 # 保留前20%\n",
        "        new_population = [scored_population[i][2].copy() for i in range(n_elite)]\n",
        "\n",
        "        # ========================================\n",
        "        # 2.4 交叉（Crossover）+ 突變（Mutation）\n",
        "        # ========================================\n",
        "        while len(new_population) < pop_size:\n",
        "            # 隨機選擇兩個父母\n",
        "            parent1, parent2 = random.sample(parents, 2)\n",
        "            # ========================================\n",
        "            # 單點交叉（Single-Point Crossover）\n",
        "            # ========================================\n",
        "            # 【如何運作】\n",
        "            # 1. 隨機選擇切割點\n",
        "            # 2. 前半來自parent1，後半來自parent2\n",
        "            #\n",
        "            # 例如：\n",
        "            # parent1: [1, 1, 0, | 0, 1, 1]\n",
        "            # parent2: [0, 1, 1, | 1, 0, 0]\n",
        "            #            ↑ 切割點\n",
        "            # child:   [1, 1, 0, | 1, 0, 0]\n",
        "\n",
        "            crossover_point = random.randint(1, len(ALL_FEATURES) - 1)\n",
        "            child = np.concatenate([parent1[:crossover_point], parent2[crossover_point:]])\n",
        "            # ========================================\n",
        "            # 突變（Mutation）\n",
        "            # ========================================\n",
        "            # 【如何運作】\n",
        "            # 以mutation_rate的機率翻轉每個基因\n",
        "            #\n",
        "            # 【為什麼需要突變】\n",
        "            # 1. 保持多樣性\n",
        "            # 2. 避免早熟收斂（整個族群變得太相似）\n",
        "            # 3. 探索新的特徵組合\n",
        "            for i in range(len(child)):\n",
        "                if random.random() < mutation_rate:\n",
        "                    child[i] = 1 - child[i] # 0變1，1變0\n",
        "\n",
        "            new_population.append(child)\n",
        "        # 更新族群\n",
        "        population = new_population\n",
        "    # ========================================\n",
        "    # 3. 返回最佳解\n",
        "    # ========================================\n",
        "    best_features = [f for i, f in enumerate(ALL_FEATURES) if best_individual[i] == 1]\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"基因演算法完成！\")\n",
        "    print(f\"最佳RMSE: {best_score:.6f}\")\n",
        "    print(f\"選出特徵數: {len(best_features)}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    return best_features, history\n",
        "\n",
        "# ========================================\n",
        "# 模擬退火\n",
        "# ========================================\n",
        "def simulated_annealing(model_class, model_name, T_init, cooling_rate,\n",
        "                       T_min, n_trials, verbose=True):\n",
        "    \"\"\"\n",
        "    模擬退火特徵選擇\n",
        "\n",
        "    【演算法靈感】\n",
        "    模擬金屬退火過程：\n",
        "    1. 高溫：原子活躍，可以移動到任何位置\n",
        "    2. 慢慢降溫：原子逐漸穩定\n",
        "    3. 低溫：原子固定在能量最低的位置\n",
        "\n",
        "    【如何運作】\n",
        "\n",
        "    ┌─────────────────────────────────────────┐\n",
        "    │ 1. 初始化                                   │\n",
        "    │    隨機選擇一組特徵                             │\n",
        "    │    設定初始溫度T = T_init                         │\n",
        "    └─────────────────────────────────────────┘\n",
        "                    ↓\n",
        "    ┌─────────────────────────────────────────┐\n",
        "    │ 2. 產生鄰居解                                 │\n",
        "    │    隨機翻轉一個特徵的選擇狀態                        │\n",
        "    │    當前: [1,0,1,1,0]                            │\n",
        "    │    鄰居: [1,1,1,1,0]  ←第2個特徵翻轉                   │\n",
        "    └─────────────────────────────────────────┘\n",
        "                    ↓\n",
        "    ┌─────────────────────────────────────────┐\n",
        "    │ 3. 計算適應度變化                               │\n",
        "    │    Δ = 鄰居的RMSE - 當前的RMSE                     │\n",
        "    └─────────────────────────────────────────┘\n",
        "                    ↓\n",
        "          ┌─────────┴─────────┐\n",
        "          │                   │\n",
        "       Δ < 0                  Δ ≥ 0\n",
        "       (變好)                     (變差)\n",
        "          │                   │\n",
        "          ↓                   ↓\n",
        "    ┌──────────┐      ┌──────────────────┐\n",
        "    │必定接受      │      │以機率P接受:            │\n",
        "    │          │      │P = exp(-Δ/T)          │\n",
        "    │          │      │                  │\n",
        "    │          │      │溫度高→P大→易接受         │\n",
        "    │          │      │溫度低→P小→難接受         │\n",
        "    └──────────┘      └──────────────────┘\n",
        "          │                   │\n",
        "          └─────────┬─────────┘\n",
        "                    ↓\n",
        "    ┌─────────────────────────────────────────┐\n",
        "    │ 4. 降溫                                    │\n",
        "    │    T = T * cooling_rate                         │\n",
        "    │    (例如：T = T * 0.85)                         │\n",
        "    └─────────────────────────────────────────┘\n",
        "                    ↓\n",
        "    ┌─────────────────────────────────────────┐\n",
        "    │ 5. 重複2-4直到T < T_min                           │\n",
        "    └─────────────────────────────────────────┘\n",
        "\n",
        "    【核心機制：接受機率】\n",
        "\n",
        "    P(接受) = exp(-Δ/T)\n",
        "\n",
        "    當Δ=10（鄰居差10單位）：\n",
        "    - T=100: P=exp(-10/100)=0.90 → 很可能接受\n",
        "    - T=50:  P=exp(-10/50)=0.82  → 可能接受\n",
        "    - T=10:  P=exp(-10/10)=0.37  → 不太接受\n",
        "    - T=1:   P=exp(-10/1)=0.00   → 幾乎不接受\n",
        "\n",
        "    【為什麼有效】\n",
        "    1. 高溫階段：\n",
        "       - 大膽探索，接受劣解\n",
        "       - 跳出局部最優\n",
        "\n",
        "    2. 中溫階段：\n",
        "       - 謹慎探索\n",
        "       - 偶爾接受劣解\n",
        "\n",
        "    3. 低溫階段：\n",
        "       - 只接受好解\n",
        "       - 收斂到最優\n",
        "\n",
        "    【與GA的區別】\n",
        "    - GA：族群並行搜索（多個解同時進化）\n",
        "    - SA：單一解逐步改進（更節省記憶體）\n",
        "\n",
        "    參數：\n",
        "    - model_class: 模型類別\n",
        "    - model_name: 模型名稱\n",
        "    - T_init: 初始溫度（控制探索程度）\n",
        "    - cooling_rate: 冷卻率（控制降溫速度）\n",
        "    - T_min: 最低溫度（停止條件）\n",
        "    - n_trials: 評估時的試驗次數\n",
        "    - verbose: 是否顯示詳細過程\n",
        "\n",
        "    返回：\n",
        "    - best_features: 最佳特徵列表\n",
        "    - history: 搜索歷史記錄\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"模擬退火 - {model_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"參數設定: 初始溫度={T_init}, 冷卻率={cooling_rate}, 最低溫度={T_min}\")\n",
        "\n",
        "    # ========================================\n",
        "    # 1. 初始化\n",
        "    # ========================================\n",
        "    # 隨機生成初始解\n",
        "    current_solution = np.random.choice([0, 1], len(ALL_FEATURES))\n",
        "    current_features = [f for i, f in enumerate(ALL_FEATURES) if current_solution[i] == 1]\n",
        "    current_score, current_std = evaluate_feature_subset(current_features, model_class, n_trials=n_trials, epochs=epochs_inner)\n",
        "    # 記錄全局最佳\n",
        "    best_solution = current_solution.copy()\n",
        "    best_score = current_score\n",
        "    best_features = current_features.copy()\n",
        "    # 記錄搜索歷史\n",
        "    history = {\n",
        "        'temperatures': [],# 溫度變化\n",
        "        'current_scores': [], # 當前解的分數\n",
        "        'best_scores': [], # 最佳解的分數\n",
        "        'n_features': [], # 特徵數量\n",
        "        'acceptance_count': 0, # 接受次數\n",
        "        'total_iterations': 0 # 總迭代次數\n",
        "    }\n",
        "\n",
        "    T = T_init\n",
        "    iteration = 0\n",
        "\n",
        "    print(f\"\\n初始解: RMSE = {current_score:.6f}±{current_std:.4f} (特徵數: {len(current_features)})\")\n",
        "\n",
        "    # ========================================\n",
        "    # 2. 退火主循環\n",
        "    # ========================================\n",
        "    while T > T_min:\n",
        "        iteration += 1\n",
        "        history['total_iterations'] = iteration\n",
        "\n",
        "        # ========================================\n",
        "        # 2.1 產生鄰居解\n",
        "        # ========================================\n",
        "        # 【鄰域定義】\n",
        "        # 翻轉一個特徵的選擇狀態\n",
        "        #\n",
        "        # 為什麼只翻轉一個？\n",
        "        # - 保證鄰居解與當前解相似\n",
        "        # - 逐步搜索，而非隨機跳躍\n",
        "\n",
        "        neighbor = current_solution.copy()\n",
        "        flip_idx = random.randint(0, len(ALL_FEATURES) - 1)\n",
        "        neighbor[flip_idx] = 1 - neighbor[flip_idx]\n",
        "        # 解碼鄰居\n",
        "        neighbor_features = [f for i, f in enumerate(ALL_FEATURES) if neighbor[i] == 1]\n",
        "        # 評估鄰居\n",
        "        if len(neighbor_features) == 0:\n",
        "            neighbor_score = np.inf\n",
        "            neighbor_std = 0\n",
        "        else:\n",
        "            neighbor_score, neighbor_std = evaluate_feature_subset(neighbor_features, model_class, n_trials=n_trials, epochs=epochs_inner)\n",
        "\n",
        "        # ========================================\n",
        "        # 2.2 決定是否接受鄰居\n",
        "        # ========================================\n",
        "        delta = neighbor_score - current_score\n",
        "\n",
        "        if delta < 0:\n",
        "          # 鄰居更好 → 必定接受\n",
        "            accept = True\n",
        "        else:\n",
        "            # 鄰居更差 → 以機率接受\n",
        "            # 【Metropolis準則】\n",
        "            # P(接受) = exp(-Δ/T)\n",
        "            #\n",
        "            # 為什麼要接受劣解？\n",
        "            # 1. 跳出局部最優\n",
        "            # 2. 探索更多可能性\n",
        "            # 3. 溫度越高，接受機率越大\n",
        "            acceptance_prob = np.exp(-delta / T)\n",
        "            accept = random.random() < acceptance_prob\n",
        "        # 接受鄰居\n",
        "        if accept:\n",
        "            current_solution = neighbor\n",
        "            current_score = neighbor_score\n",
        "            current_std = neighbor_std\n",
        "            current_features = neighbor_features\n",
        "            history['acceptance_count'] += 1\n",
        "            # 更新全局最佳\n",
        "            if current_score < best_score:\n",
        "                best_score = current_score\n",
        "                best_solution = current_solution.copy()\n",
        "                best_features = current_features.copy()\n",
        "                print(f\"  迭代 {iteration}: 發現新的最佳解！RMSE = {best_score:.6f}±{current_std:.4f} (特徵數: {len(best_features)})\")\n",
        "        # ========================================\n",
        "        # 2.3 記錄歷史\n",
        "        # ========================================\n",
        "        history['temperatures'].append(T)\n",
        "        history['current_scores'].append(current_score)\n",
        "        history['best_scores'].append(best_score)\n",
        "        history['n_features'].append(len(current_features))\n",
        "\n",
        "        if verbose and iteration % 10 == 0:\n",
        "            acc_rate = history['acceptance_count'] / iteration * 100\n",
        "            print(f\"  迭代 {iteration}: T={T:.2f}, 當前RMSE={current_score:.6f}, \"\n",
        "                  f\"最佳RMSE={best_score:.6f}, 接受率={acc_rate:.1f}%\")\n",
        "        # ========================================\n",
        "        # 2.4 降溫\n",
        "        # ========================================\n",
        "        # 【冷卻策略：指數衰減】\n",
        "        # T = T * cooling_rate\n",
        "        #\n",
        "        # 例如：cooling_rate=0.85\n",
        "        # T = 100 → 85 → 72.25 → 61.41 → ...\n",
        "        #\n",
        "        # 為什麼用指數衰減？\n",
        "        # - 開始降溫慢（充分探索）\n",
        "        # - 後期降溫快（加速收斂）\n",
        "        T *= cooling_rate\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"模擬退火完成！\")\n",
        "    print(f\"總迭代次數: {iteration}\")\n",
        "    print(f\"接受率: {history['acceptance_count']/iteration*100:.1f}%\")\n",
        "    print(f\"最佳RMSE: {best_score:.6f}\")\n",
        "    print(f\"選出特徵數: {len(best_features)}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    return best_features, history\n",
        "\n",
        "# ========================================\n",
        "# 執行特徵篩選\n",
        "# ========================================\n",
        "print(\"\\n開始執行特徵篩選...\")\n",
        "\n",
        "# GA-LSTM\n",
        "ga_trans_features, ga_trans_history = genetic_algorithm(\n",
        "    LSTMRegressor, \"LSTM\",\n",
        "    generations=ga_generations,\n",
        "    pop_size=ga_pop_size,\n",
        "    mutation_rate=ga_mutation_rate,\n",
        "    n_trials=n_trials\n",
        ")\n",
        "\n",
        "# SA-LSTM\n",
        "sa_trans_features, sa_trans_history = simulated_annealing(\n",
        "    LSTMRegressor, \"LSTM\",\n",
        "    T_init=sa_T_init,\n",
        "    cooling_rate=sa_cooling_rate,\n",
        "    T_min=sa_T_min,\n",
        "    n_trials=n_trials\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iw-e1f-djVMF",
        "outputId": "17d25184-53f5-4f21-8f67-8f4d8ff4b210"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "實驗參數設定\n",
            "================================================================================\n",
            "GA參數: 世代數=15, 族群大小=25, 變異率=0.25\n",
            "SA參數: 初始溫度=100, 冷卻率=0.95\n",
            "評估參數: 每個組合評估3次, 內部訓練40輪\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "[Part 5/6] 階段2 & 3 - 進化演算法特徵篩選\n",
            "================================================================================\n",
            "\n",
            "開始執行特徵篩選...\n",
            "\n",
            "============================================================\n",
            "基因演算法 - LSTM\n",
            "============================================================\n",
            "參數設定: 世代數=15, 族群大小=25, 變異率=0.25\n",
            "\n",
            "第 1/15 代:\n",
            "  評估進度: 5/25 (當前RMSE: 28.815964±0.1581, 特徵數: 14)\n",
            "  評估進度: 10/25 (當前RMSE: 28.534141±0.2741, 特徵數: 10)\n",
            "  評估進度: 15/25 (當前RMSE: 28.798221±0.4820, 特徵數: 11)\n",
            "  評估進度: 20/25 (當前RMSE: 28.948323±0.4210, 特徵數: 16)\n",
            "  評估進度: 25/25 (當前RMSE: 29.083147±0.0411, 特徵數: 13)\n",
            "  最佳RMSE: 28.419449±0.1737 (特徵數: 10)\n",
            "  平均RMSE: 28.821563\n",
            "  最差RMSE: 29.190613\n",
            "  發現新的最佳解！RMSE = 28.419449\n",
            "\n",
            "第 2/15 代:\n",
            "  評估進度: 5/25 (當前RMSE: 28.566579±0.2638, 特徵數: 16)\n",
            "  評估進度: 10/25 (當前RMSE: 28.772512±0.4666, 特徵數: 17)\n",
            "  評估進度: 15/25 (當前RMSE: 28.518653±0.3039, 特徵數: 10)\n",
            "  評估進度: 20/25 (當前RMSE: 28.789164±0.1989, 特徵數: 12)\n",
            "  評估進度: 25/25 (當前RMSE: 28.858426±0.1433, 特徵數: 14)\n",
            "  最佳RMSE: 28.419449±0.1737 (特徵數: 10)\n",
            "  平均RMSE: 28.791506\n",
            "  最差RMSE: 29.123262\n",
            "\n",
            "第 3/15 代:\n",
            "  評估進度: 5/25 (當前RMSE: 28.534141±0.2741, 特徵數: 10)\n",
            "  評估進度: 10/25 (當前RMSE: 28.698493±0.1875, 特徵數: 14)\n",
            "  評估進度: 15/25 (當前RMSE: 28.682477±0.2882, 特徵數: 16)\n",
            "  評估進度: 20/25 (當前RMSE: 28.744158±0.1868, 特徵數: 16)\n",
            "  評估進度: 25/25 (當前RMSE: 28.948876±0.3596, 特徵數: 16)\n",
            "  最佳RMSE: 26.428296±3.2479 (特徵數: 14)\n",
            "  平均RMSE: 28.651499\n",
            "  最差RMSE: 29.178618\n",
            "  發現新的最佳解！RMSE = 26.428296\n",
            "\n",
            "第 4/15 代:\n",
            "  評估進度: 5/25 (當前RMSE: 28.518653±0.3039, 特徵數: 10)\n",
            "  評估進度: 10/25 (當前RMSE: 28.667328±0.3574, 特徵數: 17)\n",
            "  評估進度: 15/25 (當前RMSE: 28.783070±0.2054, 特徵數: 12)\n",
            "  評估進度: 20/25 (當前RMSE: 28.676399±0.1131, 特徵數: 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 測試集評估"
      ],
      "metadata": {
        "id": "5OXxuv4zl9NG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# 最終測試集評估\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"最終測試集評估\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def final_evaluation(features, model_class, model_name):\n",
        "    \"\"\"\n",
        "    在測試集上最終評估\n",
        "\n",
        "    【為什麼需要最終評估？】\n",
        "    1. 驗證集用於GA/SA選擇特徵\n",
        "    2. 測試集用於評估真實泛化能力\n",
        "    3. 避免過擬合驗證集\n",
        "\n",
        "    【評估流程】\n",
        "    1. 用選出的特徵重新訓練模型\n",
        "    2. 在測試集上評估\n",
        "    3. 報告RMSE和MAE\n",
        "    \"\"\"\n",
        "    print(f\"\\n🔹 評估 {model_name}...\")\n",
        "    f_idx = [ALL_FEATURES.index(f) for f in features]\n",
        "\n",
        "    Xtr = X_train_scaled[:, f_idx]\n",
        "    Xte = X_test_scaled[:, f_idx]\n",
        "\n",
        "    Xtr_seq, ytr_seq = create_sequences(Xtr, y_train.values, lookback_period)\n",
        "    Xte_seq, yte_seq = create_sequences(Xte, y_test.values, lookback_period)\n",
        "\n",
        "    tr_loader = DataLoader(\n",
        "        TensorDataset(torch.Tensor(Xtr_seq), torch.Tensor(ytr_seq)),\n",
        "        batch_size=32, shuffle=True\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        TensorDataset(torch.Tensor(Xtr_seq), torch.Tensor(ytr_seq)),\n",
        "        batch_size=32\n",
        "    )\n",
        "\n",
        "    model = model_class(len(features)).to(device)\n",
        "    model = train_model(model, tr_loader, val_loader, epochs=epochs_final, verbose=True)\n",
        "    rmse, mae = evaluate_model(model, Xte_seq, yte_seq)\n",
        "\n",
        "    print(f\"{model_name} - RMSE: {rmse:.6f}, MAE: {mae:.6f}\")\n",
        "    return rmse, mae\n",
        "\n",
        "rmse_ga_trans, mae_ga_trans = final_evaluation(ga_trans_features, LSTMRegressor, \"GA-LSTM\")\n",
        "rmse_sa_trans, mae_sa_trans = final_evaluation(sa_trans_features, LSTMRegressor, \"SA-LSTM\")\n",
        "\n",
        "# ============================================================================\n",
        "# [Part 6/6] 結果分析與可視化\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"[Part 6/6] 結果分析與可視化\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "results_df = pd.DataFrame({\n",
        "    'Method': [\n",
        "        'LSTM-Baseline',\n",
        "        'LSTM-GA',\n",
        "        'LSTM-SA'\n",
        "    ],\n",
        "    'N_Features': [\n",
        "        len(ALL_FEATURES),\n",
        "        len(ga_trans_features),\n",
        "        len(sa_trans_features)\n",
        "    ],\n",
        "    'RMSE': [\n",
        "        rmse_trans_base,\n",
        "        rmse_ga_trans,\n",
        "        rmse_sa_trans\n",
        "    ],\n",
        "    'MAE': [\n",
        "        mae_trans_base,\n",
        "        mae_ga_trans,\n",
        "        mae_sa_trans\n",
        "    ]\n",
        "})\n",
        "\n",
        "results_df['RMSE_Improvement'] = (\n",
        "    (results_df['RMSE'].iloc[0] - results_df['RMSE']) / results_df['RMSE'].iloc[0] * 100\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"性能比較結果\")\n",
        "print(\"=\"*80)\n",
        "print(results_df.to_string(index=False))\n",
        "\n",
        "results_df.to_csv(os.path.join(OUTPUT_DIR, 'results_comparison.csv'), index=False)\n",
        "print(f\"\\n結果已保存至: {os.path.join(OUTPUT_DIR, 'results_comparison.csv')}\")\n",
        "\n",
        "# ========================================\n",
        "# 可視化\n",
        "# ========================================\n",
        "print(\"\\n生成可視化圖表...\")\n",
        "\n",
        "# 圖1: 性能對比\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "colors = ['#ff7f0e', '#2ca02c', '#d62728']\n",
        "x_pos = np.arange(len(results_df))\n",
        "\n",
        "axes[0].bar(x_pos, results_df['RMSE'], color=colors, alpha=0.8)\n",
        "axes[0].set_xticks(x_pos)\n",
        "axes[0].set_xticklabels(results_df['Method'], rotation=15, ha='right')\n",
        "axes[0].set_ylabel('RMSE', fontsize=12)\n",
        "axes[0].set_title('RMSE Comparison', fontsize=14, fontweight='bold')\n",
        "axes[0].grid(axis='y', alpha=0.3)\n",
        "\n",
        "for i, v in enumerate(results_df['RMSE']):\n",
        "    axes[0].text(i, v + 0.5, f'{v:.2f}', ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "axes[1].bar(x_pos, results_df['N_Features'], color=colors, alpha=0.8)\n",
        "axes[1].set_xticks(x_pos)\n",
        "axes[1].set_xticklabels(results_df['Method'], rotation=15, ha='right')\n",
        "axes[1].set_ylabel('Number of Features', fontsize=12)\n",
        "axes[1].set_title('Feature Count Comparison', fontsize=14, fontweight='bold')\n",
        "axes[1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "for i, v in enumerate(results_df['N_Features']):\n",
        "    axes[1].text(i, v + 0.5, f'{int(v)}', ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, '1_performance_comparison.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "plt.close()\n",
        "print(\"圖1: 性能對比柱狀圖\")\n",
        "\n",
        "# 圖2: GA演化過程\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "ax = axes[0, 0]\n",
        "generations = range(1, len(ga_trans_history['best_scores']) + 1)\n",
        "ax.plot(generations, ga_trans_history['best_scores'], 'g-o', label='Best', linewidth=2, markersize=6)\n",
        "ax.plot(generations, ga_trans_history['mean_scores'], 'b--s', label='Mean', linewidth=1.5, markersize=4)\n",
        "ax.plot(generations, ga_trans_history['worst_scores'], 'r:^', label='Worst', linewidth=1, markersize=4)\n",
        "ax.set_xlabel('Generation', fontsize=11)\n",
        "ax.set_ylabel('RMSE', fontsize=11)\n",
        "ax.set_title('GA Evolution Process', fontsize=13, fontweight='bold')\n",
        "ax.legend(loc='upper right')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "ax = axes[0, 1]\n",
        "ax.plot(generations, ga_trans_history['best_n_features'], 'go-', linewidth=2, markersize=6)\n",
        "ax.set_xlabel('Generation', fontsize=11)\n",
        "ax.set_ylabel('Number of Features', fontsize=11)\n",
        "ax.set_title('GA: Feature Count Evolution', fontsize=13, fontweight='bold')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "ax = axes[1, 0]\n",
        "iterations = range(1, len(sa_trans_history['temperatures']) + 1)\n",
        "ax2 = ax.twinx()\n",
        "ax.plot(iterations, sa_trans_history['temperatures'], 'r-', label='Temperature', linewidth=2, alpha=0.7)\n",
        "ax2.plot(iterations, sa_trans_history['current_scores'], 'b--', label='Current RMSE', linewidth=1.5, alpha=0.7)\n",
        "ax2.plot(iterations, sa_trans_history['best_scores'], 'g-', label='Best RMSE', linewidth=2)\n",
        "ax.set_xlabel('Iteration', fontsize=11)\n",
        "ax.set_ylabel('Temperature', fontsize=11, color='r')\n",
        "ax2.set_ylabel('RMSE', fontsize=11, color='b')\n",
        "ax.set_title('SA Annealing Process', fontsize=13, fontweight='bold')\n",
        "ax.tick_params(axis='y', labelcolor='r')\n",
        "ax2.tick_params(axis='y', labelcolor='b')\n",
        "ax.legend(loc='upper left')\n",
        "ax2.legend(loc='upper right')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "ax = axes[1, 1]\n",
        "methods = ['GA', 'SA']\n",
        "rmse_vals = [rmse_ga_trans, rmse_sa_trans]\n",
        "feat_counts = [len(ga_trans_features), len(sa_trans_features)]\n",
        "colors_comp = ['#2ca02c', '#d62728']\n",
        "\n",
        "x = np.arange(len(methods))\n",
        "width = 0.35\n",
        "\n",
        "bars1 = ax.bar(x - width/2, rmse_vals, width, label='RMSE', color=colors_comp, alpha=0.8)\n",
        "ax2 = ax.twinx()\n",
        "bars2 = ax2.bar(x + width/2, feat_counts, width, label='# Features', color='gray', alpha=0.5)\n",
        "\n",
        "ax.set_xlabel('Method', fontsize=11)\n",
        "ax.set_ylabel('RMSE', fontsize=11, color='black')\n",
        "ax2.set_ylabel('Number of Features', fontsize=11, color='gray')\n",
        "ax.set_title('GA vs SA: Performance & Feature Count', fontsize=13, fontweight='bold')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(methods)\n",
        "ax.legend(loc='upper left')\n",
        "ax2.legend(loc='upper right')\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, '2_evolution_process.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "plt.close()\n",
        "print(\"圖2: 演化過程分析\")\n",
        "\n",
        "# 圖3: 特徵選擇熱圖\n",
        "fig, ax = plt.subplots(figsize=(12, max(8, len(ALL_FEATURES) * 0.25)))\n",
        "\n",
        "feature_matrix = np.zeros((len(ALL_FEATURES), 2))\n",
        "methods = ['GA', 'SA']\n",
        "feature_sets = [ga_trans_features, sa_trans_features]\n",
        "\n",
        "for j, features in enumerate(feature_sets):\n",
        "    for feat in features:\n",
        "        i = ALL_FEATURES.index(feat)\n",
        "        feature_matrix[i, j] = 1\n",
        "\n",
        "sns.heatmap(feature_matrix,\n",
        "            xticklabels=methods,\n",
        "            yticklabels=ALL_FEATURES,\n",
        "            cmap='YlGnBu',\n",
        "            cbar_kws={'label': 'Selected'},\n",
        "            linewidths=0.5,\n",
        "            linecolor='white',\n",
        "            ax=ax)\n",
        "\n",
        "ax.set_title('Feature Selection Heatmap', fontsize=14, fontweight='bold', pad=20)\n",
        "ax.set_xlabel('Method', fontsize=12)\n",
        "ax.set_ylabel('Feature', fontsize=12)\n",
        "\n",
        "selection_counts = feature_matrix.sum(axis=1)\n",
        "for i, count in enumerate(selection_counts):\n",
        "    if count > 0:\n",
        "        ax.text(2.2, i + 0.5, f'{int(count)}x', va='center', fontsize=8,\n",
        "                bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.3))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTPUT_DIR, '3_feature_selection_heatmap.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "plt.close()\n",
        "print(\"圖3: 特徵選擇熱圖\")\n",
        "\n",
        "# ========================================\n",
        "# 特徵分析\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"特徵選擇分析\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "feature_consensus = {}\n",
        "for feat in ALL_FEATURES:\n",
        "    count = sum([1 for fs in feature_sets if feat in fs])\n",
        "    if count > 0:\n",
        "        feature_consensus[feat] = count\n",
        "\n",
        "feature_consensus = dict(sorted(feature_consensus.items(), key=lambda x: x[1], reverse=True))\n",
        "\n",
        "print(\"\\n高共識特徵 (被兩種方法都選中):\")\n",
        "high_consensus = {k: v for k, v in feature_consensus.items() if v == 2}\n",
        "for feat, count in high_consensus.items():\n",
        "    print(f\"  • {feat}: {count}/2 方法選中\")\n",
        "\n",
        "print(\"\\n僅被一種方法選中的特徵:\")\n",
        "mid_consensus = {k: v for k, v in feature_consensus.items() if v == 1}\n",
        "for feat, count in mid_consensus.items():\n",
        "    print(f\"  • {feat}: {count}/2 方法選中\")\n",
        "\n",
        "print(\"\\n從未被選中的特徵（可能是無用特徵）:\")\n",
        "never_selected = [f for f in ALL_FEATURES if f not in feature_consensus]\n",
        "for feat in never_selected:\n",
        "    print(f\"  • {feat}: 0/2 方法選中\")\n",
        "\n",
        "feature_lists = pd.DataFrame({\n",
        "    'GA-LSTM': pd.Series(ga_trans_features),\n",
        "    'SA-LSTM': pd.Series(sa_trans_features)\n",
        "})\n",
        "feature_lists.to_csv(os.path.join(OUTPUT_DIR, 'selected_features.csv'), index=False)\n",
        "print(f\"\\n特徵列表已保存至: {os.path.join(OUTPUT_DIR, 'selected_features.csv')}\")\n",
        "\n",
        "# ========================================\n",
        "# 總結報告\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"實驗總結\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\n📊 主要發現:\")\n",
        "print(f\"1. 最佳方法: {results_df.loc[results_df['RMSE'].idxmin(), 'Method']}\")\n",
        "print(f\"   - RMSE: {results_df['RMSE'].min():.6f}\")\n",
        "print(f\"   - 特徵數: {results_df.loc[results_df['RMSE'].idxmin(), 'N_Features']:.0f}\")\n",
        "print(f\"   - 相較Baseline改進: {results_df.loc[results_df['RMSE'].idxmin(), 'RMSE_Improvement']:.2f}%\")\n",
        "\n",
        "ga_rmse = results_df[results_df['Method'].str.contains('GA')]['RMSE'].values[0]\n",
        "sa_rmse = results_df[results_df['Method'].str.contains('SA')]['RMSE'].values[0]\n",
        "print(f\"\\n2. GA vs SA比較:\")\n",
        "print(f\"   - GA RMSE: {ga_rmse:.6f}\")\n",
        "print(f\"   - SA RMSE: {sa_rmse:.6f}\")\n",
        "if ga_rmse < sa_rmse:\n",
        "    print(f\"   - GA表現較佳 (優勢: {(sa_rmse-ga_rmse)/sa_rmse*100:.2f}%)\")\n",
        "else:\n",
        "    print(f\"   - SA表現較佳 (優勢: {(ga_rmse-sa_rmse)/ga_rmse*100:.2f}%)\")\n",
        "\n",
        "baseline_feats = len(ALL_FEATURES)\n",
        "avg_selected = results_df.iloc[1:]['N_Features'].mean()\n",
        "print(f\"\\n3. 特徵效率:\")\n",
        "print(f\"   - Baseline特徵數: {baseline_feats}\")\n",
        "print(f\"   - 平均選中特徵數: {avg_selected:.1f}\")\n",
        "print(f\"   - 特徵減少: {(1-avg_selected/baseline_feats)*100:.1f}%\")\n",
        "\n",
        "print(f\"\\n4. 高共識特徵 (兩種方法都選中，推薦用於未來模型):\")\n",
        "for i, (feat, count) in enumerate(list(high_consensus.items())[:15], 1):\n",
        "    print(f\"   {i}. {feat}\")\n",
        "\n",
        "print(f\"\\n5. 從未被選中的特徵 (可能是無用特徵):\")\n",
        "for i, feat in enumerate(never_selected[:10], 1):\n",
        "    print(f\"   {i}. {feat}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"所有結果已保存至:\", OUTPUT_DIR)\n",
        "print(\"=\"*80)\n",
        "print(\"\\n實驗完成！\")"
      ],
      "metadata": {
        "id": "yT3zIetnjyDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BltgigLu7Usa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}